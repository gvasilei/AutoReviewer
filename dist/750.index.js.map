{"version":3,"file":"750.index.js","mappings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vYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC/UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACpVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://typescript-action/./node_modules/langchain/dist/util/event-source-parse.js","webpack://typescript-action/./node_modules/langchain/dist/util/axios-fetch-adapter.js","webpack://typescript-action/./node_modules/langchain/dist/schema/index.js","webpack://typescript-action/./node_modules/langchain/dist/util/async_caller.js","webpack://typescript-action/./node_modules/langchain/dist/base_language/count_tokens.js","webpack://typescript-action/./node_modules/langchain/dist/base_language/index.js","webpack://typescript-action/./node_modules/langchain/dist/memory/base.js","webpack://typescript-action/./node_modules/langchain/node_modules/uuid/wrapper.mjs","webpack://typescript-action/./node_modules/langchain/dist/callbacks/base.js","webpack://typescript-action/./node_modules/langchain/dist/callbacks/handlers/tracers.js","webpack://typescript-action/./node_modules/langchain/dist/callbacks/handlers/console.js","webpack://typescript-action/./node_modules/langchain/dist/callbacks/handlers/initialize.js","webpack://typescript-action/./node_modules/langchain/dist/callbacks/manager.js","webpack://typescript-action/./node_modules/langchain/dist/chat_models/base.js","webpack://typescript-action/./node_modules/langchain/dist/chat_models/openai.js"],"sourcesContent":["/* eslint-disable prefer-template */\n/* eslint-disable default-case */\n/* eslint-disable no-plusplus */\n// Adapted from https://github.com/gfortaine/fetch-event-source/blob/main/src/parse.ts\n// due to a packaging issue in the original.\n// MIT License\nexport const EventStreamContentType = \"text/event-stream\";\n/**\n * Converts a ReadableStream into a callback pattern.\n * @param stream The input ReadableStream.\n * @param onChunk A function that will be called on each new byte chunk in the stream.\n * @returns {Promise<void>} A promise that will be resolved when the stream closes.\n */\nexport async function getBytes(stream, onChunk) {\n    const reader = stream.getReader();\n    let result;\n    // eslint-disable-next-line no-cond-assign\n    while (!(result = await reader.read()).done) {\n        onChunk(result.value);\n    }\n}\n/**\n * Parses arbitary byte chunks into EventSource line buffers.\n * Each line should be of the format \"field: value\" and ends with \\r, \\n, or \\r\\n.\n * @param onLine A function that will be called on each new EventSource line.\n * @returns A function that should be called for each incoming byte chunk.\n */\nexport function getLines(onLine) {\n    let buffer;\n    let position; // current read position\n    let fieldLength; // length of the `field` portion of the line\n    let discardTrailingNewline = false;\n    // return a function that can process each incoming byte chunk:\n    return function onChunk(arr) {\n        if (buffer === undefined) {\n            buffer = arr;\n            position = 0;\n            fieldLength = -1;\n        }\n        else {\n            // we're still parsing the old line. Append the new bytes into buffer:\n            buffer = concat(buffer, arr);\n        }\n        const bufLength = buffer.length;\n        let lineStart = 0; // index where the current line starts\n        while (position < bufLength) {\n            if (discardTrailingNewline) {\n                if (buffer[position] === 10 /* ControlChars.NewLine */) {\n                    lineStart = ++position; // skip to next char\n                }\n                discardTrailingNewline = false;\n            }\n            // start looking forward till the end of line:\n            let lineEnd = -1; // index of the \\r or \\n char\n            for (; position < bufLength && lineEnd === -1; ++position) {\n                switch (buffer[position]) {\n                    case 58 /* ControlChars.Colon */:\n                        if (fieldLength === -1) {\n                            // first colon in line\n                            fieldLength = position - lineStart;\n                        }\n                        break;\n                    // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n                    // @ts-ignore:7029 \\r case below should fallthrough to \\n:\n                    case 13 /* ControlChars.CarriageReturn */:\n                        discardTrailingNewline = true;\n                    // eslint-disable-next-line no-fallthrough\n                    case 10 /* ControlChars.NewLine */:\n                        lineEnd = position;\n                        break;\n                }\n            }\n            if (lineEnd === -1) {\n                // We reached the end of the buffer but the line hasn't ended.\n                // Wait for the next arr and then continue parsing:\n                break;\n            }\n            // we've reached the line end, send it out:\n            onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n            lineStart = position; // we're now on the next line\n            fieldLength = -1;\n        }\n        if (lineStart === bufLength) {\n            buffer = undefined; // we've finished reading it\n        }\n        else if (lineStart !== 0) {\n            // Create a new view into buffer beginning at lineStart so we don't\n            // need to copy over the previous lines when we get the new arr:\n            buffer = buffer.subarray(lineStart);\n            position -= lineStart;\n        }\n    };\n}\n/**\n * Parses line buffers into EventSourceMessages.\n * @param onId A function that will be called on each `id` field.\n * @param onRetry A function that will be called on each `retry` field.\n * @param onMessage A function that will be called on each message.\n * @returns A function that should be called for each incoming line buffer.\n */\nexport function getMessages(onMessage, onId, onRetry) {\n    let message = newMessage();\n    const decoder = new TextDecoder();\n    // return a function that can process each incoming line buffer:\n    return function onLine(line, fieldLength) {\n        if (line.length === 0) {\n            // empty line denotes end of message. Trigger the callback and start a new message:\n            onMessage?.(message);\n            message = newMessage();\n        }\n        else if (fieldLength > 0) {\n            // exclude comments and lines with no values\n            // line is of format \"<field>:<value>\" or \"<field>: <value>\"\n            // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n            const field = decoder.decode(line.subarray(0, fieldLength));\n            const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* ControlChars.Space */ ? 2 : 1);\n            const value = decoder.decode(line.subarray(valueOffset));\n            switch (field) {\n                case \"data\":\n                    // if this message already has data, append the new value to the old.\n                    // otherwise, just set to the new value:\n                    message.data = message.data ? message.data + \"\\n\" + value : value; // otherwise,\n                    break;\n                case \"event\":\n                    message.event = value;\n                    break;\n                case \"id\":\n                    onId?.((message.id = value));\n                    break;\n                case \"retry\": {\n                    const retry = parseInt(value, 10);\n                    if (!Number.isNaN(retry)) {\n                        // per spec, ignore non-integers\n                        onRetry?.((message.retry = retry));\n                    }\n                    break;\n                }\n            }\n        }\n    };\n}\nfunction concat(a, b) {\n    const res = new Uint8Array(a.length + b.length);\n    res.set(a);\n    res.set(b, a.length);\n    return res;\n}\nfunction newMessage() {\n    // data, event, and id must be initialized to empty strings:\n    // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n    // retry should be initialized to undefined so we return a consistent shape\n    // to the js engine all the time: https://mathiasbynens.be/notes/shapes-ics#takeaways\n    return {\n        data: \"\",\n        event: \"\",\n        id: \"\",\n        retry: undefined,\n    };\n}\n","/* eslint-disable no-plusplus */\n/* eslint-disable prefer-template */\n/* eslint-disable prefer-arrow-callback */\n/* eslint-disable no-var */\n/* eslint-disable vars-on-top */\n/* eslint-disable no-param-reassign */\n/* eslint-disable import/no-extraneous-dependencies */\n/**\n * This is copied from @vespaiach/axios-fetch-adapter, which exposes an ESM\n * module without setting the \"type\" field in package.json.\n */\nimport axios from \"axios\";\nimport { EventStreamContentType, getLines, getBytes, getMessages, } from \"./event-source-parse.js\";\nfunction tryJsonStringify(data) {\n    try {\n        return JSON.stringify(data);\n    }\n    catch (e) {\n        return data;\n    }\n}\n/**\n * In order to avoid import issues with axios 1.x, copying here the internal\n * utility functions that we used to import directly from axios.\n */\n// Copied from axios/lib/core/settle.js\nfunction settle(resolve, reject, response) {\n    const { validateStatus } = response.config;\n    if (!response.status || !validateStatus || validateStatus(response.status)) {\n        resolve(response);\n    }\n    else {\n        reject(createError(`Request failed with status code ${response.status} and body ${typeof response.data === \"string\"\n            ? response.data\n            : tryJsonStringify(response.data)}`, response.config, null, response.request, response));\n    }\n}\n// Copied from axios/lib/helpers/isAbsoluteURL.js\nfunction isAbsoluteURL(url) {\n    // A URL is considered absolute if it begins with \"<scheme>://\" or \"//\" (protocol-relative URL).\n    // RFC 3986 defines scheme name as a sequence of characters beginning with a letter and followed\n    // by any combination of letters, digits, plus, period, or hyphen.\n    return /^([a-z][a-z\\d+\\-.]*:)?\\/\\//i.test(url);\n}\n// Copied from axios/lib/helpers/combineURLs.js\nfunction combineURLs(baseURL, relativeURL) {\n    return relativeURL\n        ? baseURL.replace(/\\/+$/, \"\") + \"/\" + relativeURL.replace(/^\\/+/, \"\")\n        : baseURL;\n}\n// Copied from axios/lib/helpers/buildURL.js\nfunction encode(val) {\n    return encodeURIComponent(val)\n        .replace(/%3A/gi, \":\")\n        .replace(/%24/g, \"$\")\n        .replace(/%2C/gi, \",\")\n        .replace(/%20/g, \"+\")\n        .replace(/%5B/gi, \"[\")\n        .replace(/%5D/gi, \"]\");\n}\nfunction buildURL(url, params, paramsSerializer) {\n    if (!params) {\n        return url;\n    }\n    var serializedParams;\n    if (paramsSerializer) {\n        serializedParams = paramsSerializer(params);\n    }\n    else if (isURLSearchParams(params)) {\n        serializedParams = params.toString();\n    }\n    else {\n        var parts = [];\n        forEach(params, function serialize(val, key) {\n            if (val === null || typeof val === \"undefined\") {\n                return;\n            }\n            if (isArray(val)) {\n                key = `${key}[]`;\n            }\n            else {\n                val = [val];\n            }\n            forEach(val, function parseValue(v) {\n                if (isDate(v)) {\n                    v = v.toISOString();\n                }\n                else if (isObject(v)) {\n                    v = JSON.stringify(v);\n                }\n                parts.push(`${encode(key)}=${encode(v)}`);\n            });\n        });\n        serializedParams = parts.join(\"&\");\n    }\n    if (serializedParams) {\n        var hashmarkIndex = url.indexOf(\"#\");\n        if (hashmarkIndex !== -1) {\n            url = url.slice(0, hashmarkIndex);\n        }\n        url += (url.indexOf(\"?\") === -1 ? \"?\" : \"&\") + serializedParams;\n    }\n    return url;\n}\n// Copied from axios/lib/core/buildFullPath.js\nfunction buildFullPath(baseURL, requestedURL) {\n    if (baseURL && !isAbsoluteURL(requestedURL)) {\n        return combineURLs(baseURL, requestedURL);\n    }\n    return requestedURL;\n}\n// Copied from axios/lib/utils.js\nfunction isUndefined(val) {\n    return typeof val === \"undefined\";\n}\nfunction isObject(val) {\n    return val !== null && typeof val === \"object\";\n}\nfunction isDate(val) {\n    return toString.call(val) === \"[object Date]\";\n}\nfunction isURLSearchParams(val) {\n    return toString.call(val) === \"[object URLSearchParams]\";\n}\nfunction isArray(val) {\n    return Array.isArray(val);\n}\nfunction forEach(obj, fn) {\n    // Don't bother if no value provided\n    if (obj === null || typeof obj === \"undefined\") {\n        return;\n    }\n    // Force an array if not already something iterable\n    if (typeof obj !== \"object\") {\n        obj = [obj];\n    }\n    if (isArray(obj)) {\n        // Iterate over array values\n        for (var i = 0, l = obj.length; i < l; i++) {\n            fn.call(null, obj[i], i, obj);\n        }\n    }\n    else {\n        // Iterate over object keys\n        for (var key in obj) {\n            if (Object.prototype.hasOwnProperty.call(obj, key)) {\n                fn.call(null, obj[key], key, obj);\n            }\n        }\n    }\n}\nfunction isFormData(val) {\n    return toString.call(val) === \"[object FormData]\";\n}\n// TODO this needs to be fixed to run in newer browser-like environments\n// https://github.com/vespaiach/axios-fetch-adapter/issues/20#issue-1396365322\nfunction isStandardBrowserEnv() {\n    if (typeof navigator !== \"undefined\" &&\n        // eslint-disable-next-line no-undef\n        (navigator.product === \"ReactNative\" ||\n            // eslint-disable-next-line no-undef\n            navigator.product === \"NativeScript\" ||\n            // eslint-disable-next-line no-undef\n            navigator.product === \"NS\")) {\n        return false;\n    }\n    return typeof window !== \"undefined\" && typeof document !== \"undefined\";\n}\n/**\n * - Create a request object\n * - Get response body\n * - Check if timeout\n */\nexport default async function fetchAdapter(config) {\n    const request = createRequest(config);\n    const data = await getResponse(request, config);\n    return new Promise((resolve, reject) => {\n        if (data instanceof Error) {\n            reject(data);\n        }\n        else {\n            // eslint-disable-next-line no-unused-expressions\n            Object.prototype.toString.call(config.settle) === \"[object Function]\"\n                ? config.settle(resolve, reject, data)\n                : settle(resolve, reject, data);\n        }\n    });\n}\n/**\n * Fetch API stage two is to get response body. This funtion tries to retrieve\n * response body based on response's type\n */\nasync function getResponse(request, config) {\n    let stageOne;\n    try {\n        stageOne = await fetch(request);\n    }\n    catch (e) {\n        if (e && e.name === \"AbortError\") {\n            return createError(\"Request aborted\", config, \"ECONNABORTED\", request);\n        }\n        if (e && e.name === \"TimeoutError\") {\n            return createError(\"Request timeout\", config, \"ECONNABORTED\", request);\n        }\n        return createError(\"Network Error\", config, \"ERR_NETWORK\", request);\n    }\n    const headers = {};\n    stageOne.headers.forEach((value, key) => {\n        headers[key] = value;\n    });\n    const response = {\n        ok: stageOne.ok,\n        status: stageOne.status,\n        statusText: stageOne.statusText,\n        headers,\n        config,\n        request,\n    };\n    if (stageOne.status >= 200 && stageOne.status !== 204) {\n        if (config.responseType === \"stream\") {\n            const contentType = stageOne.headers.get(\"content-type\");\n            if (!contentType?.startsWith(EventStreamContentType)) {\n                // If the content-type is not stream, response is most likely an error\n                if (stageOne.status >= 400) {\n                    // If the error is a JSON, parse it. Otherwise, return as text\n                    if (contentType?.startsWith(\"application/json\")) {\n                        response.data = await stageOne.json();\n                        return response;\n                    }\n                    else {\n                        response.data = await stageOne.text();\n                        return response;\n                    }\n                }\n                // If the non-stream response is also not an error, throw\n                throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n            }\n            await getBytes(stageOne.body, getLines(getMessages(config.onmessage)));\n        }\n        else {\n            switch (config.responseType) {\n                case \"arraybuffer\":\n                    response.data = await stageOne.arrayBuffer();\n                    break;\n                case \"blob\":\n                    response.data = await stageOne.blob();\n                    break;\n                case \"json\":\n                    response.data = await stageOne.json();\n                    break;\n                case \"formData\":\n                    response.data = await stageOne.formData();\n                    break;\n                default:\n                    response.data = await stageOne.text();\n                    break;\n            }\n        }\n    }\n    return response;\n}\n/**\n * This function will create a Request object based on configuration's axios\n */\nfunction createRequest(config) {\n    const headers = new Headers(config.headers);\n    // HTTP basic authentication\n    if (config.auth) {\n        const username = config.auth.username || \"\";\n        const password = config.auth.password\n            ? decodeURI(encodeURIComponent(config.auth.password))\n            : \"\";\n        headers.set(\"Authorization\", `Basic ${btoa(`${username}:${password}`)}`);\n    }\n    const method = config.method.toUpperCase();\n    const options = {\n        headers,\n        method,\n    };\n    if (method !== \"GET\" && method !== \"HEAD\") {\n        options.body = config.data;\n        // In these cases the browser will automatically set the correct Content-Type,\n        // but only if that header hasn't been set yet. So that's why we're deleting it.\n        if (isFormData(options.body) && isStandardBrowserEnv()) {\n            headers.delete(\"Content-Type\");\n        }\n    }\n    if (config.mode) {\n        options.mode = config.mode;\n    }\n    if (config.cache) {\n        options.cache = config.cache;\n    }\n    if (config.integrity) {\n        options.integrity = config.integrity;\n    }\n    if (config.redirect) {\n        options.redirect = config.redirect;\n    }\n    if (config.referrer) {\n        options.referrer = config.referrer;\n    }\n    if (config.timeout && config.timeout > 0) {\n        options.signal = AbortSignal.timeout(config.timeout);\n    }\n    if (config.signal) {\n        // this overrides the timeout signal if both are set\n        options.signal = config.signal;\n    }\n    // This config is similar to XHRâ€™s withCredentials flag, but with three available values instead of two.\n    // So if withCredentials is not set, default value 'same-origin' will be used\n    if (!isUndefined(config.withCredentials)) {\n        options.credentials = config.withCredentials ? \"include\" : \"omit\";\n    }\n    // for streaming\n    if (config.responseType === \"stream\") {\n        options.headers.set(\"Accept\", EventStreamContentType);\n    }\n    const fullPath = buildFullPath(config.baseURL, config.url);\n    const url = buildURL(fullPath, config.params, config.paramsSerializer);\n    // Expected browser to throw error if there is any wrong configuration value\n    return new Request(url, options);\n}\n/**\n * Note:\n *\n *   From version >= 0.27.0, createError function is replaced by AxiosError class.\n *   So I copy the old createError function here for backward compatible.\n *\n *\n *\n * Create an Error with the specified message, config, error code, request and response.\n *\n * @param {string} message The error message.\n * @param {Object} config The config.\n * @param {string} [code] The error code (for example, 'ECONNABORTED').\n * @param {Object} [request] The request.\n * @param {Object} [response] The response.\n * @returns {Error} The created error.\n */\nfunction createError(message, config, code, request, response) {\n    if (axios.AxiosError && typeof axios.AxiosError === \"function\") {\n        return new axios.AxiosError(message, axios.AxiosError[code], config, request, response);\n    }\n    const error = new Error(message);\n    return enhanceError(error, config, code, request, response);\n}\n/**\n *\n * Note:\n *\n *   This function is for backward compatible.\n *\n *\n * Update an Error with the specified config, error code, and response.\n *\n * @param {Error} error The error to update.\n * @param {Object} config The config.\n * @param {string} [code] The error code (for example, 'ECONNABORTED').\n * @param {Object} [request] The request.\n * @param {Object} [response] The response.\n * @returns {Error} The error.\n */\nfunction enhanceError(error, config, code, request, response) {\n    error.config = config;\n    if (code) {\n        error.code = code;\n    }\n    error.request = request;\n    error.response = response;\n    error.isAxiosError = true;\n    error.toJSON = function toJSON() {\n        return {\n            // Standard\n            message: this.message,\n            name: this.name,\n            // Microsoft\n            description: this.description,\n            number: this.number,\n            // Mozilla\n            fileName: this.fileName,\n            lineNumber: this.lineNumber,\n            columnNumber: this.columnNumber,\n            stack: this.stack,\n            // Axios\n            config: this.config,\n            code: this.code,\n            status: this.response && this.response.status ? this.response.status : null,\n        };\n    };\n    return error;\n}\n","export const RUN_KEY = \"__run\";\nexport class BaseChatMessage {\n    constructor(text) {\n        /** The text of the message. */\n        Object.defineProperty(this, \"text\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        /** The name of the message sender in a multi-user chat. */\n        Object.defineProperty(this, \"name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.text = text;\n    }\n}\nexport class HumanChatMessage extends BaseChatMessage {\n    _getType() {\n        return \"human\";\n    }\n}\nexport class AIChatMessage extends BaseChatMessage {\n    _getType() {\n        return \"ai\";\n    }\n}\nexport class SystemChatMessage extends BaseChatMessage {\n    _getType() {\n        return \"system\";\n    }\n}\nexport class ChatMessage extends BaseChatMessage {\n    constructor(text, role) {\n        super(text);\n        Object.defineProperty(this, \"role\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.role = role;\n    }\n    _getType() {\n        return \"generic\";\n    }\n}\n/**\n * Base PromptValue class. All prompt values should extend this class.\n */\nexport class BasePromptValue {\n}\n/**\n * Base Index class. All indexes should extend this class.\n */\nexport class BaseRetriever {\n}\nexport class BaseChatMessageHistory {\n}\nexport class BaseCache {\n}\nexport class BaseFileStore {\n}\n","import pRetry from \"p-retry\";\nimport PQueueMod from \"p-queue\";\nconst STATUS_NO_RETRY = [\n    400,\n    401,\n    403,\n    404,\n    405,\n    406,\n    407,\n    408,\n    409, // Conflict\n];\n/**\n * A class that can be used to make async calls with concurrency and retry logic.\n *\n * This is useful for making calls to any kind of \"expensive\" external resource,\n * be it because it's rate-limited, subject to network issues, etc.\n *\n * Concurrent calls are limited by the `maxConcurrency` parameter, which defaults\n * to `Infinity`. This means that by default, all calls will be made in parallel.\n *\n * Retries are limited by the `maxRetries` parameter, which defaults to 6. This\n * means that by default, each call will be retried up to 6 times, with an\n * exponential backoff between each attempt.\n */\nexport class AsyncCaller {\n    constructor(params) {\n        Object.defineProperty(this, \"maxConcurrency\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"maxRetries\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"queue\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.maxConcurrency = params.maxConcurrency ?? Infinity;\n        this.maxRetries = params.maxRetries ?? 6;\n        const PQueue = \"default\" in PQueueMod ? PQueueMod.default : PQueueMod;\n        this.queue = new PQueue({ concurrency: this.maxConcurrency });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    call(callable, ...args) {\n        return this.queue.add(() => pRetry(() => callable(...args).catch((error) => {\n            // eslint-disable-next-line no-instanceof/no-instanceof\n            if (error instanceof Error) {\n                throw error;\n            }\n            else {\n                throw new Error(error);\n            }\n        }), {\n            onFailedAttempt(error) {\n                if (error.message.startsWith(\"Cancel\") ||\n                    error.message.startsWith(\"TimeoutError\") ||\n                    error.message.startsWith(\"AbortError\")) {\n                    throw error;\n                }\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                if (error?.code === \"ECONNABORTED\") {\n                    throw error;\n                }\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                const status = error?.response?.status;\n                if (status && STATUS_NO_RETRY.includes(+status)) {\n                    throw error;\n                }\n            },\n            retries: this.maxRetries,\n            randomize: true,\n            // If needed we can change some of the defaults here,\n            // but they're quite sensible.\n        }), { throwOnTimeout: true });\n    }\n    fetch(...args) {\n        return this.call(() => fetch(...args).then((res) => (res.ok ? res : Promise.reject(res))));\n    }\n}\n","// https://www.npmjs.com/package/@dqbd/tiktoken\nexport const getModelNameForTiktoken = (modelName) => {\n    if (modelName.startsWith(\"gpt-3.5-turbo-\")) {\n        return \"gpt-3.5-turbo\";\n    }\n    if (modelName.startsWith(\"gpt-4-32k-\")) {\n        return \"gpt-4-32k\";\n    }\n    if (modelName.startsWith(\"gpt-4-\")) {\n        return \"gpt-4\";\n    }\n    return modelName;\n};\nexport const getEmbeddingContextSize = (modelName) => {\n    switch (modelName) {\n        case \"text-embedding-ada-002\":\n            return 8191;\n        default:\n            return 2046;\n    }\n};\nexport const getModelContextSize = (modelName) => {\n    switch (getModelNameForTiktoken(modelName)) {\n        case \"gpt-3.5-turbo\":\n            return 4096;\n        case \"gpt-4-32k\":\n            return 32768;\n        case \"gpt-4\":\n            return 8192;\n        case \"text-davinci-003\":\n            return 4097;\n        case \"text-curie-001\":\n            return 2048;\n        case \"text-babbage-001\":\n            return 2048;\n        case \"text-ada-001\":\n            return 2048;\n        case \"code-davinci-002\":\n            return 8000;\n        case \"code-cushman-001\":\n            return 2048;\n        default:\n            return 4097;\n    }\n};\nexport const importTiktoken = async () => {\n    try {\n        const { encoding_for_model } = await import(\"@dqbd/tiktoken\");\n        return { encoding_for_model };\n    }\n    catch (error) {\n        console.log(error);\n        return { encoding_for_model: null };\n    }\n};\nexport const calculateMaxTokens = async ({ prompt, modelName, }) => {\n    const { encoding_for_model } = await importTiktoken();\n    // fallback to approximate calculation if tiktoken is not available\n    let numTokens = Math.ceil(prompt.length / 4);\n    try {\n        if (encoding_for_model) {\n            const encoding = encoding_for_model(getModelNameForTiktoken(modelName));\n            const tokenized = encoding.encode(prompt);\n            numTokens = tokenized.length;\n            encoding.free();\n        }\n    }\n    catch (error) {\n        console.warn(\"Failed to calculate number of tokens with tiktoken, falling back to approximate count\", error);\n    }\n    const maxTokens = getModelContextSize(modelName);\n    return maxTokens - numTokens;\n};\n","import { AsyncCaller } from \"../util/async_caller.js\";\nimport { getModelNameForTiktoken, importTiktoken } from \"./count_tokens.js\";\nconst getVerbosity = () => false;\n/**\n * Base class for language models, chains, tools.\n */\nexport class BaseLangChain {\n    constructor(params) {\n        /**\n         * Whether to print out response text.\n         */\n        Object.defineProperty(this, \"verbose\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"callbacks\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.verbose = params.verbose ?? getVerbosity();\n        this.callbacks = params.callbacks;\n    }\n}\n/**\n * Base class for language models.\n */\nexport class BaseLanguageModel extends BaseLangChain {\n    constructor(params) {\n        super({\n            verbose: params.verbose,\n            callbacks: params.callbacks ?? params.callbackManager,\n        });\n        /**\n         * The async caller should be used by subclasses to make any async calls,\n         * which will thus benefit from the concurrency and retry logic.\n         */\n        Object.defineProperty(this, \"caller\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"_encoding\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"_registry\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.caller = new AsyncCaller(params ?? {});\n    }\n    async getNumTokens(text) {\n        // fallback to approximate calculation if tiktoken is not available\n        let numTokens = Math.ceil(text.length / 4);\n        try {\n            if (!this._encoding) {\n                const { encoding_for_model } = await importTiktoken();\n                // modelName only exists in openai subclasses, but tiktoken only supports\n                // openai tokenisers anyway, so for other subclasses we default to gpt2\n                if (encoding_for_model) {\n                    this._encoding = encoding_for_model(\"modelName\" in this\n                        ? getModelNameForTiktoken(this.modelName)\n                        : \"gpt2\");\n                    // We need to register a finalizer to free the tokenizer when the\n                    // model is garbage collected.\n                    this._registry = new FinalizationRegistry((t) => t.free());\n                    this._registry.register(this, this._encoding);\n                }\n            }\n            if (this._encoding) {\n                numTokens = this._encoding.encode(text).length;\n            }\n        }\n        catch (error) {\n            console.warn(\"Failed to calculate number of tokens with tiktoken, falling back to approximate count\", error);\n        }\n        return numTokens;\n    }\n    /**\n     * Get the identifying parameters of the LLM.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    _identifyingParams() {\n        return {};\n    }\n    /**\n     * Return a json-like object representing this LLM.\n     */\n    serialize() {\n        return {\n            ...this._identifyingParams(),\n            _type: this._llmType(),\n            _model: this._modelType(),\n        };\n    }\n    /**\n     * Load an LLM from a json-like object describing it.\n     */\n    static async deserialize(data) {\n        const { _type, _model, ...rest } = data;\n        if (_model && _model !== \"base_chat_model\") {\n            throw new Error(`Cannot load LLM with model ${_model}`);\n        }\n        const Cls = {\n            openai: (await import(\"../chat_models/openai.js\")).ChatOpenAI,\n        }[_type];\n        if (Cls === undefined) {\n            throw new Error(`Cannot load  LLM with type ${_type}`);\n        }\n        return new Cls(rest);\n    }\n}\n","export class BaseMemory {\n}\n/**\n * This function is used by memory classes to select the input value\n * to use for the memory. If there is only one input value, it is used.\n * If there are multiple input values, the inputKey must be specified.\n */\nexport const getInputValue = (inputValues, inputKey) => {\n    if (inputKey !== undefined) {\n        return inputValues[inputKey];\n    }\n    const keys = Object.keys(inputValues);\n    if (keys.length === 1) {\n        return inputValues[keys[0]];\n    }\n    throw new Error(`input values have multiple keys, memory only supported when one key currently: ${keys}`);\n};\n/**\n * This function is used by memory classes to get a string representation\n * of the chat message history, based on the message content and role.\n */\nexport function getBufferString(messages, humanPrefix = \"Human\", aiPrefix = \"AI\") {\n    const string_messages = [];\n    for (const m of messages) {\n        let role;\n        if (m._getType() === \"human\") {\n            role = humanPrefix;\n        }\n        else if (m._getType() === \"ai\") {\n            role = aiPrefix;\n        }\n        else if (m._getType() === \"system\") {\n            role = \"System\";\n        }\n        else if (m._getType() === \"generic\") {\n            role = m.role;\n        }\n        else {\n            throw new Error(`Got unsupported message type: ${m}`);\n        }\n        string_messages.push(`${role}: ${m.text}`);\n    }\n    return string_messages.join(\"\\n\");\n}\n","import uuid from './dist/index.js';\nexport const v1 = uuid.v1;\nexport const v3 = uuid.v3;\nexport const v4 = uuid.v4;\nexport const v5 = uuid.v5;\nexport const NIL = uuid.NIL;\nexport const version = uuid.version;\nexport const validate = uuid.validate;\nexport const stringify = uuid.stringify;\nexport const parse = uuid.parse;\n","import { v4 as uuidv4 } from \"uuid\";\nclass BaseCallbackHandlerMethodsClass {\n}\nexport class BaseCallbackHandler extends BaseCallbackHandlerMethodsClass {\n    constructor(input) {\n        super();\n        Object.defineProperty(this, \"ignoreLLM\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"ignoreChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"ignoreAgent\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        if (input) {\n            this.ignoreLLM = input.ignoreLLM ?? this.ignoreLLM;\n            this.ignoreChain = input.ignoreChain ?? this.ignoreChain;\n            this.ignoreAgent = input.ignoreAgent ?? this.ignoreAgent;\n        }\n    }\n    copy() {\n        return new this.constructor(this);\n    }\n    static fromMethods(methods) {\n        class Handler extends BaseCallbackHandler {\n            constructor() {\n                super();\n                Object.defineProperty(this, \"name\", {\n                    enumerable: true,\n                    configurable: true,\n                    writable: true,\n                    value: uuidv4()\n                });\n                Object.assign(this, methods);\n            }\n        }\n        return new Handler();\n    }\n}\n","import { BaseCallbackHandler } from \"../base.js\";\nexport class BaseTracer extends BaseCallbackHandler {\n    constructor() {\n        super();\n        Object.defineProperty(this, \"session\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"runMap\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new Map()\n        });\n    }\n    copy() {\n        return this;\n    }\n    async newSession(sessionName) {\n        const sessionCreate = {\n            start_time: Date.now(),\n            name: sessionName,\n        };\n        const session = await this.persistSession(sessionCreate);\n        this.session = session;\n        return session;\n    }\n    _addChildRun(parentRun, childRun) {\n        if (childRun.type === \"llm\") {\n            parentRun.child_llm_runs.push(childRun);\n        }\n        else if (childRun.type === \"chain\") {\n            parentRun.child_chain_runs.push(childRun);\n        }\n        else if (childRun.type === \"tool\") {\n            parentRun.child_tool_runs.push(childRun);\n        }\n        else {\n            throw new Error(\"Invalid run type\");\n        }\n    }\n    _startTrace(run) {\n        if (run.parent_uuid) {\n            const parentRun = this.runMap.get(run.parent_uuid);\n            if (parentRun) {\n                if (!(parentRun.type === \"tool\" || parentRun.type === \"chain\")) {\n                    throw new Error(\"Caller run can only be a tool or chain\");\n                }\n                else {\n                    this._addChildRun(parentRun, run);\n                }\n            }\n            else {\n                throw new Error(`Caller run ${run.parent_uuid} not found`);\n            }\n        }\n        this.runMap.set(run.uuid, run);\n    }\n    async _endTrace(run) {\n        if (!run.parent_uuid) {\n            await this.persistRun(run);\n        }\n        else {\n            const parentRun = this.runMap.get(run.parent_uuid);\n            if (parentRun === undefined) {\n                throw new Error(`Parent run ${run.parent_uuid} not found`);\n            }\n            parentRun.child_execution_order = Math.max(parentRun.child_execution_order, run.child_execution_order);\n        }\n        this.runMap.delete(run.uuid);\n    }\n    _getExecutionOrder(parentRunId) {\n        // If a run has no parent then execution order is 1\n        if (parentRunId === undefined) {\n            return 1;\n        }\n        const parentRun = this.runMap.get(parentRunId);\n        if (parentRun === undefined) {\n            throw new Error(`Parent run ${parentRunId} not found`);\n        }\n        return parentRun.child_execution_order + 1;\n    }\n    async handleLLMStart(llm, prompts, runId, parentRunId) {\n        if (this.session === undefined) {\n            this.session = await this.loadDefaultSession();\n        }\n        const execution_order = this._getExecutionOrder(parentRunId);\n        const run = {\n            uuid: runId,\n            parent_uuid: parentRunId,\n            start_time: Date.now(),\n            end_time: 0,\n            serialized: llm,\n            prompts,\n            session_id: this.session.id,\n            execution_order,\n            child_execution_order: execution_order,\n            type: \"llm\",\n        };\n        this._startTrace(run);\n        await this.onLLMStart?.(run);\n    }\n    async handleLLMEnd(output, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"llm\") {\n            throw new Error(\"No LLM run to end.\");\n        }\n        const llmRun = run;\n        llmRun.end_time = Date.now();\n        llmRun.response = output;\n        await this.onLLMEnd?.(llmRun);\n        await this._endTrace(llmRun);\n    }\n    async handleLLMError(error, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"llm\") {\n            throw new Error(\"No LLM run to end.\");\n        }\n        const llmRun = run;\n        llmRun.end_time = Date.now();\n        llmRun.error = error.message;\n        await this.onLLMError?.(llmRun);\n        await this._endTrace(llmRun);\n    }\n    async handleChainStart(chain, inputs, runId, parentRunId) {\n        if (this.session === undefined) {\n            this.session = await this.loadDefaultSession();\n        }\n        const execution_order = this._getExecutionOrder(parentRunId);\n        const run = {\n            uuid: runId,\n            parent_uuid: parentRunId,\n            start_time: Date.now(),\n            end_time: 0,\n            serialized: chain,\n            inputs,\n            session_id: this.session.id,\n            execution_order,\n            child_execution_order: execution_order,\n            type: \"chain\",\n            child_llm_runs: [],\n            child_chain_runs: [],\n            child_tool_runs: [],\n        };\n        this._startTrace(run);\n        await this.onChainStart?.(run);\n    }\n    async handleChainEnd(outputs, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"chain\") {\n            throw new Error(\"No chain run to end.\");\n        }\n        const chainRun = run;\n        chainRun.end_time = Date.now();\n        chainRun.outputs = outputs;\n        await this.onChainEnd?.(chainRun);\n        await this._endTrace(chainRun);\n    }\n    async handleChainError(error, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"chain\") {\n            throw new Error(\"No chain run to end.\");\n        }\n        const chainRun = run;\n        chainRun.end_time = Date.now();\n        chainRun.error = error.message;\n        await this.onChainError?.(chainRun);\n        await this._endTrace(chainRun);\n    }\n    async handleToolStart(tool, input, runId, parentRunId) {\n        if (this.session === undefined) {\n            this.session = await this.loadDefaultSession();\n        }\n        const execution_order = this._getExecutionOrder(parentRunId);\n        const run = {\n            uuid: runId,\n            parent_uuid: parentRunId,\n            start_time: Date.now(),\n            end_time: 0,\n            serialized: tool,\n            tool_input: input,\n            session_id: this.session.id,\n            execution_order,\n            child_execution_order: execution_order,\n            type: \"tool\",\n            action: JSON.stringify(tool),\n            child_llm_runs: [],\n            child_chain_runs: [],\n            child_tool_runs: [],\n        };\n        this._startTrace(run);\n        await this.onToolStart?.(run);\n    }\n    async handleToolEnd(output, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"tool\") {\n            throw new Error(\"No tool run to end\");\n        }\n        const toolRun = run;\n        toolRun.end_time = Date.now();\n        toolRun.output = output;\n        await this.onToolEnd?.(toolRun);\n        await this._endTrace(toolRun);\n    }\n    async handleToolError(error, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"tool\") {\n            throw new Error(\"No tool run to end\");\n        }\n        const toolRun = run;\n        toolRun.end_time = Date.now();\n        toolRun.error = error.message;\n        await this.onToolError?.(toolRun);\n        await this._endTrace(toolRun);\n    }\n    async handleAgentAction(action, runId) {\n        const run = this.runMap.get(runId);\n        if (!run || run?.type !== \"chain\") {\n            return;\n        }\n        const agentRun = run;\n        agentRun.actions = agentRun.actions || [];\n        agentRun.actions.push(action);\n        await this.onAgentAction?.(run);\n    }\n}\nexport class LangChainTracer extends BaseTracer {\n    constructor() {\n        super();\n        Object.defineProperty(this, \"name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"langchain_tracer\"\n        });\n        Object.defineProperty(this, \"endpoint\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.LANGCHAIN_ENDPOINT\n                : undefined) || \"http://localhost:8000\"\n        });\n        Object.defineProperty(this, \"headers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: {\n                \"Content-Type\": \"application/json\",\n            }\n        });\n        // eslint-disable-next-line no-process-env\n        if (typeof process !== \"undefined\" && process.env?.LANGCHAIN_API_KEY) {\n            // eslint-disable-next-line no-process-env\n            this.headers[\"x-api-key\"] = process.env?.LANGCHAIN_API_KEY;\n        }\n    }\n    async persistRun(run) {\n        let endpoint;\n        if (run.type === \"llm\") {\n            endpoint = `${this.endpoint}/llm-runs`;\n        }\n        else if (run.type === \"chain\") {\n            endpoint = `${this.endpoint}/chain-runs`;\n        }\n        else {\n            endpoint = `${this.endpoint}/tool-runs`;\n        }\n        const response = await fetch(endpoint, {\n            method: \"POST\",\n            headers: this.headers,\n            body: JSON.stringify(run),\n        });\n        if (!response.ok) {\n            console.error(`Failed to persist run: ${response.status} ${response.statusText}`);\n        }\n    }\n    async persistSession(sessionCreate) {\n        const endpoint = `${this.endpoint}/sessions`;\n        const response = await fetch(endpoint, {\n            method: \"POST\",\n            headers: this.headers,\n            body: JSON.stringify(sessionCreate),\n        });\n        if (!response.ok) {\n            console.error(`Failed to persist session: ${response.status} ${response.statusText}, using default session.`);\n            return {\n                id: 1,\n                ...sessionCreate,\n            };\n        }\n        return {\n            id: (await response.json()).id,\n            ...sessionCreate,\n        };\n    }\n    async loadSession(sessionName) {\n        const endpoint = `${this.endpoint}/sessions?name=${sessionName}`;\n        return this._handleSessionResponse(endpoint);\n    }\n    async loadDefaultSession() {\n        const endpoint = `${this.endpoint}/sessions?name=default`;\n        return this._handleSessionResponse(endpoint);\n    }\n    async _handleSessionResponse(endpoint) {\n        const response = await fetch(endpoint, {\n            method: \"GET\",\n            headers: this.headers,\n        });\n        let tracerSession;\n        if (!response.ok) {\n            console.error(`Failed to load session: ${response.status} ${response.statusText}`);\n            tracerSession = {\n                id: 1,\n                start_time: Date.now(),\n            };\n            this.session = tracerSession;\n            return tracerSession;\n        }\n        const resp = (await response.json());\n        if (resp.length === 0) {\n            tracerSession = {\n                id: 1,\n                start_time: Date.now(),\n            };\n            this.session = tracerSession;\n            return tracerSession;\n        }\n        [tracerSession] = resp;\n        this.session = tracerSession;\n        return tracerSession;\n    }\n}\n","import styles from \"ansi-styles\";\nimport { BaseTracer, } from \"./tracers.js\";\nfunction wrap(style, text) {\n    return `${style.open}${text}${style.close}`;\n}\nfunction tryJsonStringify(obj, fallback) {\n    try {\n        return JSON.stringify(obj, null, 2);\n    }\n    catch (err) {\n        return fallback;\n    }\n}\nfunction elapsed(run) {\n    const elapsed = run.end_time - run.start_time;\n    if (elapsed < 1000) {\n        return `${elapsed}ms`;\n    }\n    return `${(elapsed / 1000).toFixed(2)}s`;\n}\nconst { color } = styles;\nexport class ConsoleCallbackHandler extends BaseTracer {\n    // boilerplate to work with the base tracer class\n    constructor() {\n        super();\n        Object.defineProperty(this, \"name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"console_callback_handler\"\n        });\n        Object.defineProperty(this, \"i\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n    }\n    persistSession(session) {\n        // eslint-disable-next-line no-plusplus\n        return Promise.resolve({ ...session, id: this.i++ });\n    }\n    persistRun(_run) {\n        return Promise.resolve();\n    }\n    loadDefaultSession() {\n        return this.newSession();\n    }\n    loadSession(sessionName) {\n        return this.newSession(sessionName);\n    }\n    // utility methods\n    getParents(run) {\n        const parents = [];\n        let currentRun = run;\n        while (currentRun.parent_uuid) {\n            const parent = this.runMap.get(currentRun.parent_uuid);\n            if (parent) {\n                parents.push(parent);\n                currentRun = parent;\n            }\n            else {\n                break;\n            }\n        }\n        return parents;\n    }\n    getBreadcrumbs(run) {\n        const parents = this.getParents(run).reverse();\n        const string = [...parents, run]\n            .map((parent, i, arr) => {\n            const name = `${parent.execution_order}:${parent.type}:${parent.serialized?.name}`;\n            return i === arr.length - 1 ? wrap(styles.bold, name) : name;\n        })\n            .join(\" > \");\n        return wrap(color.grey, string);\n    }\n    // logging methods\n    onChainStart(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.green, \"[chain/start]\")} [${crumbs}] Entering Chain run with input: ${tryJsonStringify(run.inputs, \"[inputs]\")}`);\n    }\n    onChainEnd(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.cyan, \"[chain/end]\")} [${crumbs}] [${elapsed(run)}] Exiting Chain run with output: ${tryJsonStringify(run.outputs, \"[outputs]\")}`);\n    }\n    onChainError(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.red, \"[chain/error]\")} [${crumbs}] [${elapsed(run)}] Chain run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n    }\n    onLLMStart(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.green, \"[llm/start]\")} [${crumbs}] Entering LLM run with input: ${tryJsonStringify({ prompts: run.prompts.map((p) => p.trim()) }, \"[inputs]\")}`);\n    }\n    onLLMEnd(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.cyan, \"[llm/end]\")} [${crumbs}] [${elapsed(run)}] Exiting LLM run with output: ${tryJsonStringify(run.response, \"[response]\")}`);\n    }\n    onLLMError(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.red, \"[llm/error]\")} [${crumbs}] [${elapsed(run)}] LLM run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n    }\n    onToolStart(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.green, \"[tool/start]\")} [${crumbs}] Entering Tool run with input: \"${run.tool_input?.trim()}\"`);\n    }\n    onToolEnd(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.cyan, \"[tool/end]\")} [${crumbs}] [${elapsed(run)}] Exiting Tool run with output: \"${run.output?.trim()}\"`);\n    }\n    onToolError(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.red, \"[tool/error]\")} [${crumbs}] [${elapsed(run)}] Tool run errored with error: ${tryJsonStringify(run.error, \"[error]\")}`);\n    }\n    onAgentAction(run) {\n        const crumbs = this.getBreadcrumbs(run);\n        console.log(`${wrap(color.blue, \"[agent/action]\")} [${crumbs}] Agent selected action: ${tryJsonStringify(run.actions[run.actions.length - 1], \"[action]\")}`);\n    }\n}\n","import { LangChainTracer } from \"./tracers.js\";\nexport async function getTracingCallbackHandler(session) {\n    const tracer = new LangChainTracer();\n    if (session) {\n        await tracer.loadSession(session);\n    }\n    else {\n        await tracer.loadDefaultSession();\n    }\n    return tracer;\n}\n","import { v4 as uuidv4 } from \"uuid\";\nimport { BaseCallbackHandler } from \"./base.js\";\nimport { ConsoleCallbackHandler } from \"./handlers/console.js\";\nimport { getTracingCallbackHandler } from \"./handlers/initialize.js\";\nexport class BaseCallbackManager {\n    setHandler(handler) {\n        return this.setHandlers([handler]);\n    }\n}\nclass BaseRunManager {\n    constructor(runId, handlers, inheritableHandlers, _parentRunId) {\n        Object.defineProperty(this, \"runId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: runId\n        });\n        Object.defineProperty(this, \"handlers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: handlers\n        });\n        Object.defineProperty(this, \"inheritableHandlers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: inheritableHandlers\n        });\n        Object.defineProperty(this, \"_parentRunId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: _parentRunId\n        });\n    }\n    async handleText(text) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            try {\n                await handler.handleText?.(text, this.runId, this._parentRunId);\n            }\n            catch (err) {\n                console.error(`Error in handler ${handler.constructor.name}, handleText: ${err}`);\n            }\n        }));\n    }\n}\nexport class CallbackManagerForLLMRun extends BaseRunManager {\n    async handleLLMNewToken(token) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreLLM) {\n                try {\n                    await handler.handleLLMNewToken?.(token, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleLLMNewToken: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleLLMError(err) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreLLM) {\n                try {\n                    await handler.handleLLMError?.(err, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleLLMError: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleLLMEnd(output) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreLLM) {\n                try {\n                    await handler.handleLLMEnd?.(output, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleLLMEnd: ${err}`);\n                }\n            }\n        }));\n    }\n}\nexport class CallbackManagerForChainRun extends BaseRunManager {\n    getChild() {\n        // eslint-disable-next-line @typescript-eslint/no-use-before-define\n        const manager = new CallbackManager(this.runId);\n        manager.setHandlers(this.inheritableHandlers);\n        return manager;\n    }\n    async handleChainError(err) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreChain) {\n                try {\n                    await handler.handleChainError?.(err, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleChainError: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleChainEnd(output) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreChain) {\n                try {\n                    await handler.handleChainEnd?.(output, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleChainEnd: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleAgentAction(action) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreAgent) {\n                try {\n                    await handler.handleAgentAction?.(action, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleAgentAction: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleAgentEnd(action) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreAgent) {\n                try {\n                    await handler.handleAgentEnd?.(action, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleAgentEnd: ${err}`);\n                }\n            }\n        }));\n    }\n}\nexport class CallbackManagerForToolRun extends BaseRunManager {\n    getChild() {\n        // eslint-disable-next-line @typescript-eslint/no-use-before-define\n        const manager = new CallbackManager(this.runId);\n        manager.setHandlers(this.inheritableHandlers);\n        return manager;\n    }\n    async handleToolError(err) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreAgent) {\n                try {\n                    await handler.handleToolError?.(err, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleToolError: ${err}`);\n                }\n            }\n        }));\n    }\n    async handleToolEnd(output) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreAgent) {\n                try {\n                    await handler.handleToolEnd?.(output, this.runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleToolEnd: ${err}`);\n                }\n            }\n        }));\n    }\n}\nexport class CallbackManager extends BaseCallbackManager {\n    constructor(parentRunId) {\n        super();\n        Object.defineProperty(this, \"handlers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inheritableHandlers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"name\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"callback_manager\"\n        });\n        Object.defineProperty(this, \"_parentRunId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.handlers = [];\n        this.inheritableHandlers = [];\n        this._parentRunId = parentRunId;\n    }\n    async handleLLMStart(llm, prompts, runId = uuidv4()) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreLLM) {\n                try {\n                    await handler.handleLLMStart?.(llm, prompts, runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleLLMStart: ${err}`);\n                }\n            }\n        }));\n        return new CallbackManagerForLLMRun(runId, this.handlers, this.inheritableHandlers, this._parentRunId);\n    }\n    async handleChainStart(chain, inputs, runId = uuidv4()) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreChain) {\n                try {\n                    await handler.handleChainStart?.(chain, inputs, runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleChainStart: ${err}`);\n                }\n            }\n        }));\n        return new CallbackManagerForChainRun(runId, this.handlers, this.inheritableHandlers, this._parentRunId);\n    }\n    async handleToolStart(tool, input, runId = uuidv4()) {\n        await Promise.all(this.handlers.map(async (handler) => {\n            if (!handler.ignoreAgent) {\n                try {\n                    await handler.handleToolStart?.(tool, input, runId, this._parentRunId);\n                }\n                catch (err) {\n                    console.error(`Error in handler ${handler.constructor.name}, handleToolStart: ${err}`);\n                }\n            }\n        }));\n        return new CallbackManagerForToolRun(runId, this.handlers, this.inheritableHandlers, this._parentRunId);\n    }\n    addHandler(handler, inherit = true) {\n        this.handlers.push(handler);\n        if (inherit) {\n            this.inheritableHandlers.push(handler);\n        }\n    }\n    removeHandler(handler) {\n        this.handlers = this.handlers.filter((_handler) => _handler !== handler);\n        this.inheritableHandlers = this.inheritableHandlers.filter((_handler) => _handler !== handler);\n    }\n    setHandlers(handlers, inherit = true) {\n        this.handlers = [];\n        this.inheritableHandlers = [];\n        for (const handler of handlers) {\n            this.addHandler(handler, inherit);\n        }\n    }\n    copy(additionalHandlers = [], inherit = true) {\n        const manager = new CallbackManager(this._parentRunId);\n        for (const handler of this.handlers) {\n            const inheritable = this.inheritableHandlers.includes(handler);\n            const copied = handler.copy();\n            manager.addHandler(copied, inheritable);\n        }\n        for (const handler of additionalHandlers) {\n            if (\n            // Prevent multiple copies of console_callback_handler\n            manager.handlers\n                .filter((h) => h.name === \"console_callback_handler\")\n                .some((h) => h.name === handler.name)) {\n                continue;\n            }\n            manager.addHandler(handler.copy(), inherit);\n        }\n        return manager;\n    }\n    static fromHandlers(handlers) {\n        class Handler extends BaseCallbackHandler {\n            constructor() {\n                super();\n                Object.defineProperty(this, \"name\", {\n                    enumerable: true,\n                    configurable: true,\n                    writable: true,\n                    value: uuidv4()\n                });\n                Object.assign(this, handlers);\n            }\n        }\n        const manager = new this();\n        manager.addHandler(new Handler());\n        return manager;\n    }\n    static async configure(inheritableHandlers, localHandlers, options) {\n        let callbackManager;\n        if (inheritableHandlers || localHandlers) {\n            if (Array.isArray(inheritableHandlers) || !inheritableHandlers) {\n                callbackManager = new CallbackManager();\n                callbackManager.setHandlers(inheritableHandlers?.map(ensureHandler) ?? [], true);\n            }\n            else {\n                callbackManager = inheritableHandlers;\n            }\n            callbackManager = callbackManager.copy(Array.isArray(localHandlers)\n                ? localHandlers.map(ensureHandler)\n                : localHandlers?.handlers, false);\n        }\n        const tracingEnabled = typeof process !== \"undefined\"\n            ? // eslint-disable-next-line no-process-env\n                process.env?.LANGCHAIN_TRACING !== undefined\n            : false;\n        if (options?.verbose || tracingEnabled) {\n            if (!callbackManager) {\n                callbackManager = new CallbackManager();\n            }\n            if (options?.verbose &&\n                !callbackManager.handlers.some((handler) => handler.name === ConsoleCallbackHandler.prototype.name)) {\n                const consoleHandler = new ConsoleCallbackHandler();\n                callbackManager.addHandler(consoleHandler, true);\n            }\n            if (tracingEnabled &&\n                !callbackManager.handlers.some((handler) => handler.name === \"langchain_tracer\")) {\n                const session = typeof process !== \"undefined\"\n                    ? // eslint-disable-next-line no-process-env\n                        process.env?.LANGCHAIN_SESSION\n                    : undefined;\n                callbackManager.addHandler(await getTracingCallbackHandler(session), true);\n            }\n        }\n        return callbackManager;\n    }\n}\nfunction ensureHandler(handler) {\n    if (\"name\" in handler) {\n        return handler;\n    }\n    return BaseCallbackHandler.fromMethods(handler);\n}\n","import { AIChatMessage, RUN_KEY, } from \"../schema/index.js\";\nimport { BaseLanguageModel, } from \"../base_language/index.js\";\nimport { getBufferString } from \"../memory/base.js\";\nimport { CallbackManager, } from \"../callbacks/manager.js\";\nexport class BaseChatModel extends BaseLanguageModel {\n    constructor(fields) {\n        super(fields);\n    }\n    async generate(messages, stop, callbacks) {\n        const generations = [];\n        const llmOutputs = [];\n        const messageStrings = messages.map((messageList) => getBufferString(messageList));\n        const callbackManager_ = await CallbackManager.configure(callbacks, this.callbacks, { verbose: this.verbose });\n        const runManager = await callbackManager_?.handleLLMStart({ name: this._llmType() }, messageStrings);\n        try {\n            const results = await Promise.all(messages.map((messageList) => this._generate(messageList, stop, runManager)));\n            for (const result of results) {\n                if (result.llmOutput) {\n                    llmOutputs.push(result.llmOutput);\n                }\n                generations.push(result.generations);\n            }\n        }\n        catch (err) {\n            await runManager?.handleLLMError(err);\n            throw err;\n        }\n        const output = {\n            generations,\n            llmOutput: llmOutputs.length\n                ? this._combineLLMOutput?.(...llmOutputs)\n                : undefined,\n        };\n        await runManager?.handleLLMEnd(output);\n        Object.defineProperty(output, RUN_KEY, {\n            value: runManager ? { runId: runManager?.runId } : undefined,\n            configurable: true,\n        });\n        return output;\n    }\n    _modelType() {\n        return \"base_chat_model\";\n    }\n    async generatePrompt(promptValues, stop, callbacks) {\n        const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());\n        return this.generate(promptMessages, stop, callbacks);\n    }\n    async call(messages, stop, callbacks) {\n        const result = await this.generate([messages], stop, callbacks);\n        const generations = result.generations;\n        return generations[0][0].message;\n    }\n    async callPrompt(promptValue, stop, callbacks) {\n        const promptMessages = promptValue.toChatMessages();\n        return this.call(promptMessages, stop, callbacks);\n    }\n}\nexport class SimpleChatModel extends BaseChatModel {\n    async _generate(messages, stop, runManager) {\n        const text = await this._call(messages, stop, runManager);\n        const message = new AIChatMessage(text);\n        return {\n            generations: [\n                {\n                    text: message.text,\n                    message,\n                },\n            ],\n        };\n    }\n}\n","import { Configuration, OpenAIApi, } from \"openai\";\nimport fetchAdapter from \"../util/axios-fetch-adapter.js\";\nimport { BaseChatModel, } from \"./base.js\";\nimport { AIChatMessage, ChatMessage, HumanChatMessage, SystemChatMessage, } from \"../schema/index.js\";\nimport { getModelNameForTiktoken } from \"../base_language/count_tokens.js\";\nfunction messageTypeToOpenAIRole(type) {\n    switch (type) {\n        case \"system\":\n            return \"system\";\n        case \"ai\":\n            return \"assistant\";\n        case \"human\":\n            return \"user\";\n        default:\n            throw new Error(`Unknown message type: ${type}`);\n    }\n}\nfunction openAIResponseToChatMessage(role, text) {\n    switch (role) {\n        case \"user\":\n            return new HumanChatMessage(text);\n        case \"assistant\":\n            return new AIChatMessage(text);\n        case \"system\":\n            return new SystemChatMessage(text);\n        default:\n            return new ChatMessage(text, role ?? \"unknown\");\n    }\n}\n/**\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n */\nexport class ChatOpenAI extends BaseChatModel {\n    constructor(fields, configuration) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo\"\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        const apiKey = fields?.openAIApiKey ??\n            (typeof process !== \"undefined\"\n                ? // eslint-disable-next-line no-process-env\n                    process.env?.OPENAI_API_KEY\n                : undefined);\n        if (!apiKey) {\n            throw new Error(\"OpenAI API key not found\");\n        }\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.maxTokens = fields?.maxTokens;\n        this.n = fields?.n ?? this.n;\n        this.logitBias = fields?.logitBias;\n        this.stop = fields?.stop;\n        this.streaming = fields?.streaming ?? false;\n        if (this.streaming && this.n > 1) {\n            throw new Error(\"Cannot stream results when n > 1\");\n        }\n        this.clientConfig = {\n            apiKey,\n            ...configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams() {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n            n: this.n,\n            logit_bias: this.logitBias,\n            stop: this.stop,\n            stream: this.streaming,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return this._identifyingParams();\n    }\n    /** @ignore */\n    async _generate(messages, stopOrOptions, runManager) {\n        const stop = Array.isArray(stopOrOptions)\n            ? stopOrOptions\n            : stopOrOptions?.stop;\n        const options = Array.isArray(stopOrOptions)\n            ? {}\n            : stopOrOptions?.options ?? {};\n        const tokenUsage = {};\n        if (this.stop && stop) {\n            throw new Error(\"Stop found in input and default params\");\n        }\n        const params = this.invocationParams();\n        params.stop = stop ?? params.stop;\n        const messagesMapped = messages.map((message) => ({\n            role: messageTypeToOpenAIRole(message._getType()),\n            content: message.text,\n            name: message.name,\n        }));\n        const data = params.stream\n            ? await new Promise((resolve, reject) => {\n                let response;\n                let rejected = false;\n                this.completionWithRetry({\n                    ...params,\n                    messages: messagesMapped,\n                }, {\n                    ...options,\n                    responseType: \"stream\",\n                    onmessage: (event) => {\n                        if (event.data?.trim?.() === \"[DONE]\") {\n                            resolve(response);\n                        }\n                        else {\n                            const message = JSON.parse(event.data);\n                            // on the first message set the response properties\n                            if (!response) {\n                                response = {\n                                    id: message.id,\n                                    object: message.object,\n                                    created: message.created,\n                                    model: message.model,\n                                    choices: [],\n                                };\n                            }\n                            // on all messages, update choice\n                            const part = message.choices[0];\n                            if (part != null) {\n                                let choice = response.choices.find((c) => c.index === part.index);\n                                if (!choice) {\n                                    choice = {\n                                        index: part.index,\n                                        finish_reason: part.finish_reason ?? undefined,\n                                    };\n                                    response.choices.push(choice);\n                                }\n                                if (!choice.message) {\n                                    choice.message = {\n                                        role: part.delta\n                                            ?.role,\n                                        content: part.delta?.content ?? \"\",\n                                    };\n                                }\n                                choice.message.content += part.delta?.content ?? \"\";\n                                // eslint-disable-next-line no-void\n                                void runManager?.handleLLMNewToken(part.delta?.content ?? \"\");\n                            }\n                        }\n                    },\n                }).catch((error) => {\n                    if (!rejected) {\n                        rejected = true;\n                        reject(error);\n                    }\n                });\n            })\n            : await this.completionWithRetry({\n                ...params,\n                messages: messagesMapped,\n            }, options);\n        const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, } = data.usage ?? {};\n        if (completionTokens) {\n            tokenUsage.completionTokens =\n                (tokenUsage.completionTokens ?? 0) + completionTokens;\n        }\n        if (promptTokens) {\n            tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;\n        }\n        if (totalTokens) {\n            tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;\n        }\n        const generations = [];\n        for (const part of data.choices) {\n            const role = part.message?.role ?? undefined;\n            const text = part.message?.content ?? \"\";\n            generations.push({\n                text,\n                message: openAIResponseToChatMessage(role, text),\n            });\n        }\n        return {\n            generations,\n            llmOutput: { tokenUsage },\n        };\n    }\n    async getNumTokensFromMessages(messages) {\n        let totalCount = 0;\n        let tokensPerMessage = 0;\n        let tokensPerName = 0;\n        // From: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n        if (getModelNameForTiktoken(this.modelName) === \"gpt-3.5-turbo\") {\n            tokensPerMessage = 4;\n            tokensPerName = -1;\n        }\n        else if (getModelNameForTiktoken(this.modelName).startsWith(\"gpt-4\")) {\n            tokensPerMessage = 3;\n            tokensPerName = 1;\n        }\n        const countPerMessage = await Promise.all(messages.map(async (message) => {\n            const textCount = await this.getNumTokens(message.text);\n            const count = textCount + tokensPerMessage + (message.name ? tokensPerName : 0);\n            totalCount += count;\n            return count;\n        }));\n        return { totalCount, countPerMessage };\n    }\n    /** @ignore */\n    async completionWithRetry(request, options) {\n        if (!this.client) {\n            const clientConfig = new Configuration({\n                ...this.clientConfig,\n                baseOptions: {\n                    timeout: this.timeout,\n                    adapter: fetchAdapter,\n                    ...this.clientConfig.baseOptions,\n                },\n            });\n            this.client = new OpenAIApi(clientConfig);\n        }\n        return this.caller\n            .call(this.client.createChatCompletion.bind(this.client), request, options)\n            .then((res) => res.data);\n    }\n    _llmType() {\n        return \"openai\";\n    }\n    /** @ignore */\n    _combineLLMOutput(...llmOutputs) {\n        return llmOutputs.reduce((acc, llmOutput) => {\n            if (llmOutput && llmOutput.tokenUsage) {\n                acc.tokenUsage.completionTokens +=\n                    llmOutput.tokenUsage.completionTokens ?? 0;\n                acc.tokenUsage.promptTokens += llmOutput.tokenUsage.promptTokens ?? 0;\n                acc.tokenUsage.totalTokens += llmOutput.tokenUsage.totalTokens ?? 0;\n            }\n            return acc;\n        }, {\n            tokenUsage: {\n                completionTokens: 0,\n                promptTokens: 0,\n                totalTokens: 0,\n            },\n        });\n    }\n}\n"],"names":[],"sourceRoot":""}